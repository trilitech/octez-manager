# Integration Test Sharding

This directory uses time-based sharding to balance CI test execution across parallel jobs.

## Overview

Instead of splitting tests by category (node, baker, dal, accuser, import), we distribute tests across **shards** based on their execution time. This ensures all CI jobs finish around the same time, minimizing total wall-clock time.

## Files

- **`shards.json`** - Manifest mapping tests to shards
  - Checked into git, versioned
  - Generated by `scripts/generate-shard-manifest.py`
  - Updated manually when test balance degrades

- **`run-tests.sh`** - Test runner with shard support
  - Legacy mode: `./run-tests.sh node` (run by category)
  - Shard mode: `./run-tests.sh --shard 1` (run shard 1)
  - All mode: `./run-tests.sh all` (run all tests)

## Shard Manifest Structure

```json
{
  "metadata": {
    "generated_at": "2026-01-21T12:00:00",
    "total_tests": 62,
    "total_duration": 913.5,
    "shard_count": 4
  },
  "shard-1": {
    "tests": [
      "node/09-snapshot-import.sh",
      "baker/41-baker-with-dal-node.sh",
      ...
    ],
    "test_count": 16,
    "total_duration": 231.0
  },
  ...
}
```

## How It Works

### 1. Test Collection
Tests in all categories are timed during execution:
```bash
# In run-tests.sh
start=$(date +%s.%N)
bash test.sh
end=$(date +%s.%N)
echo "TIMING: /tests/node/01-install.sh $(echo $end - $start | bc)" >> /tmp/test-timings.log
```

### 2. Shard Generation
The Python script uses **greedy bin-packing** (Longest Processing Time algorithm):

```python
# 1. Sort tests by duration (longest first)
sorted_tests = sorted(tests.items(), key=lambda x: x[1], reverse=True)

# 2. Assign each test to least-loaded shard
for test, duration in sorted_tests:
    min_shard = min(shards, key=lambda s: s["total_duration"])
    min_shard["tests"].append(test)
    min_shard["total_duration"] += duration
```

This produces near-optimal balance in O(n log n) time.

### 3. CI Execution
GitHub Actions runs 4 jobs in parallel:

```yaml
strategy:
  matrix:
    shard: [1, 2, 3, 4]

steps:
  - run: docker compose exec -T cli-tester /run-tests.sh --shard ${{ matrix.shard }}
```

Each job runs a subset of tests with approximately equal total duration.

## Updating Shards

### When to Update

Update `shards.json` when:
- Many tests added/removed
- Test durations changed significantly
- Shard imbalance >20% (one shard takes much longer than others)
- Quarterly maintenance

### How to Update

#### Option 1: From CI Logs (Recommended)

```bash
# 1. Download latest CI run logs
gh run view <run-id> --log > ci-logs.txt

# 2. Extract timings
grep "TIMING:" ci-logs.txt > test-timings.txt

# 3. Generate new manifest
python3 scripts/generate-shard-manifest.py test-timings.txt > test/integration/cli-tester/tests/shards.json

# 4. Review balance
cat test/integration/cli-tester/tests/shards.json | jq '.metadata'

# 5. Commit
git add test/integration/cli-tester/tests/shards.json
git commit -m "chore(ci): update shard manifest"
```

#### Option 2: From Local Test Run

```bash
# 1. Run all tests locally
cd test/integration
docker compose up -d --build
docker compose exec -T cli-tester /run-tests.sh all 2>&1 | tee test-run.log

# 2. Extract timings from container
docker compose exec -T cli-tester cat /tmp/test-timings.log > test-timings.txt

# 3. Generate manifest
python3 ../../scripts/generate-shard-manifest.py test-timings.txt \
  > cli-tester/tests/shards.json

# 4. Verify and commit
git add cli-tester/tests/shards.json
git commit -m "chore(ci): update shard manifest"
```

## Manifest Generator Options

```bash
# Basic usage
python3 scripts/generate-shard-manifest.py timings.txt > shards.json

# Custom shard count
python3 scripts/generate-shard-manifest.py timings.txt --shards 6 > shards.json

# Quiet mode (no stderr summary)
python3 scripts/generate-shard-manifest.py timings.txt --quiet > shards.json
```

The script outputs:
- **stdout**: JSON manifest
- **stderr**: Human-readable summary with balance statistics

## Balance Metrics

The manifest includes a **balance coefficient** (coefficient of variation):

```
CV = (standard_deviation / mean) * 100
```

- **<10%** - Excellent balance
- **10-20%** - Good balance
- **>20%** - Consider rebalancing

Example:
```
Shard 1: 231.0s
Shard 2: 232.0s
Shard 3: 225.0s
Shard 4: 225.0s

Mean: 228.25s
Std dev: 3.77s
CV: 1.65% ← Excellent!
```

## Local Development

During development, you can still run tests by category:

```bash
# Run all node tests
./run-tests.sh node

# Run all tests
./run-tests.sh all

# Run specific shard (for debugging CI issues)
./run-tests.sh --shard 2
```

## Benefits

### Before Sharding (Category-based)
```
Job: node     [████████████████████████] 8 min
Job: baker    [████████████████        ] 6 min
Job: accuser  [████████                ] 4 min
Job: dal      [██████                  ] 3 min
Job: import   [████                    ] 2 min

Total CI time: 8 min (limited by slowest)
Parallelism efficiency: ~60%
```

### After Sharding (Time-based, 4 shards)
```
Job: shard-1  [████████████████        ] 4 min
Job: shard-2  [████████████████        ] 4 min
Job: shard-3  [███████████████         ] 3.8 min
Job: shard-4  [███████████████         ] 3.8 min

Total CI time: ~4 min
Parallelism efficiency: ~95%
Speedup: 50% faster!
```

## Troubleshooting

### "Shard manifest not found"
- Check that `shards.json` exists in `test/integration/cli-tester/tests/`
- Ensure it's committed to git (not in .gitignore)

### "No tests found for shard N"
- Verify shard ID is valid (1-4)
- Check manifest has `shard-N` key with non-empty tests array

### Shard timing is way off
- Timing estimates may be inaccurate
- Run full test suite to collect real timings
- Regenerate manifest from actual data

### One shard much slower than others
- Normal variance: 10-20% is acceptable
- Large variance: >30% indicates need for rebalancing
- Update manifest from latest timings

## Future Enhancements

Potential improvements:
- Automated scheduled updates (weekly PR with new manifest)
- Dynamic shard count based on test count
- Per-test historical timing database
- Smart test ordering (flaky tests first for fast failure)
